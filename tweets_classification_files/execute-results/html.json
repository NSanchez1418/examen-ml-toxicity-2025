{
  "hash": "136f253c79d6f2c9d59bbe6bcb9d859b",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Tweets Classification\"\ncode-fold: false\njupyter: python3\nexecute:\n  echo: true\n  warning: false\n  error: true\n  cache: false\n  freeze: false\nformat:\n  html:\n    fig-format: png\n    df-print: paged\n---\n\n::: {#eb2e045d .cell execution_count=1}\n``` {.python .cell-code}\nimport sys, matplotlib\nprint(\"Python:\", sys.version.split()[0])\nprint(\"Matplotlib backend:\", matplotlib.get_backend())\n\nimport matplotlib.pyplot as plt\nplt.plot([0,1,2],[0,1,0])\nplt.title(\"Gr√°fico de prueba\")\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPython: 3.11.0\nMatplotlib backend: module://matplotlib_inline.backend_inline\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](tweets_classification_files/figure-html/cell-2-output-2.png){}\n:::\n:::\n\n\n## ## Objetivo\nClasificar cuentas en **real vs. bot** a partir de tweets (texto + metadatos), creando un target heur√≠stico y armando un pipeline con TF-IDF + OneHotEncoder + StandardScaler + LogisticRegression.\n\n## Dataset\nFuente: CSV p√∫blico (Twitter) ‚Äì 158,873 filas; 26 columnas.\n\n## Selecci√≥n del target (user_type)\nSe defini√≥ **user_type ‚àà {bot, real}** mediante una **heur√≠stica d√©bil** basada en se√±ales (foto de perfil, seguidores, edad de cuenta, etc.). Esta etiqueta sirve para entrenar un modelo que **generalice** el patr√≥n.\n\n## Columnas eliminadas\nSe eliminaron IDs, URLs, timestamps crudos y campos redundantes (p. ej., `tweetId`, `tweetUrl`, `authorProfilePic`, `createdAt`, `mentions`, `hashtag\ns`, `source`, etc.) por no aportar valor predictivo directo.\n\n## Pipeline\n- **Texto**: `TfidfVectorizer(stop_words=spanish, ngram_range=(1,2), min_df=5, max_df=0.90, max_features=50000)`\n- **Categ√≥ricas**: `OneHotEncoder(drop='if_binary')` en `isReply`, `authorVerified`\n- **Num√©ricas**: `StandardScaler(with_mean=False)` en `authorFollowers`, `mentions_count`, `hashtags_count`, `time_response`, `content_length`\n- **Modelo**: `LogisticRegression(max_iter=10000, class_weight={'bot': 2.5, 'real': 1.0})`\n\n# Importar librer√≠as b√°sicas\n\n::: {#218e4175 .cell execution_count=2}\n``` {.python .cell-code}\nimport pandas as pd\n```\n:::\n\n\n# Librer√≠as de preprocesamiento y modelo\n\n::: {#629506f1 .cell execution_count=3}\n``` {.python .cell-code}\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler, LabelEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.tree import DecisionTreeClassifier\n```\n:::\n\n\n# Librer√≠as de texto\n\n::: {#af642894 .cell execution_count=4}\n``` {.python .cell-code}\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n```\n:::\n\n\n# Evaluaci√≥n\n\n::: {#46ab12ad .cell execution_count=5}\n``` {.python .cell-code}\nfrom sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n```\n:::\n\n\n# Otras utilidades\n\n::: {#5600fafd .cell execution_count=6}\n``` {.python .cell-code}\nfrom IPython.display import display\nimport nltk\nnltk.download('stopwords')\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\nTrue\n```\n:::\n:::\n\n\n# Cargar dataset desde GitHub\n\n::: {#3e2fbc3a .cell execution_count=7}\n``` {.python .cell-code}\nurl = \"https://raw.githubusercontent.com/erickedu85/dataset/refs/heads/master/tweets/tweets_totales_con_sentimiento_ml.csv\"\n\ndf = pd.read_csv(url)\n```\n:::\n\n\n# Verificar las primeras filas y la estructura general\n\n::: {#f1457113 .cell execution_count=8}\n``` {.python .cell-code}\ndisplay(df.head(10))\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweetId</th>\n      <th>tweetUrl</th>\n      <th>content</th>\n      <th>isReply</th>\n      <th>replyTo</th>\n      <th>createdAt</th>\n      <th>authorId</th>\n      <th>authorName</th>\n      <th>authorUsername</th>\n      <th>authorVerified</th>\n      <th>...</th>\n      <th>conversationId</th>\n      <th>inReplyToId</th>\n      <th>Date</th>\n      <th>time_response</th>\n      <th>account_age_days</th>\n      <th>mentions_count</th>\n      <th>hashtags_count</th>\n      <th>content_length</th>\n      <th>has_profile_picture</th>\n      <th>sentiment_polarity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1877190873579950336</td>\n      <td>https://x.com/hectorjalonm/status/187719087357...</td>\n      <td>@DiegoPonguill10 @DanielNoboaOk @LuisaGonzalez...</td>\n      <td>True</td>\n      <td>DiegoPonguill10</td>\n      <td>2025-01-09 03:09:00</td>\n      <td>1458536175119986688</td>\n      <td>h√©ctor üåµ</td>\n      <td>hectorjalonm</td>\n      <td>False</td>\n      <td>...</td>\n      <td>1877115691146306005</td>\n      <td>1877188297551650816</td>\n      <td>2025-01-08 22:10:30</td>\n      <td>298.5</td>\n      <td>1151</td>\n      <td>3</td>\n      <td>0</td>\n      <td>88</td>\n      <td>True</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1877188297551650816</td>\n      <td>https://x.com/DiegoPonguill10/status/187718829...</td>\n      <td>@hectorjalonm @DanielNoboaOk @LuisaGonzalezEc ...</td>\n      <td>True</td>\n      <td>hectorjalonm</td>\n      <td>2025-01-09 02:59:00</td>\n      <td>1555549203211976704</td>\n      <td>Diego Ponguillo Vargas TODO TODITO #5 üòâ HLVS!!</td>\n      <td>DiegoPonguill10</td>\n      <td>False</td>\n      <td>...</td>\n      <td>1877115691146306005</td>\n      <td>1877123519743451648</td>\n      <td>2025-01-08 22:10:30</td>\n      <td>288.5</td>\n      <td>883</td>\n      <td>3</td>\n      <td>0</td>\n      <td>119</td>\n      <td>True</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1877186248986501120</td>\n      <td>https://x.com/ekuador_593/status/1877186248986...</td>\n      <td>@Gregori58965636 @yesendiaz @DanielNoboaOk Otr...</td>\n      <td>True</td>\n      <td>Gregori58965636</td>\n      <td>2025-01-09 02:50:00</td>\n      <td>1457524470365708288</td>\n      <td>Sebasti√°n Noboa Ec</td>\n      <td>ekuador_593</td>\n      <td>False</td>\n      <td>...</td>\n      <td>1877115691146306005</td>\n      <td>1877122565782576896</td>\n      <td>2025-01-08 22:10:30</td>\n      <td>279.5</td>\n      <td>1153</td>\n      <td>3</td>\n      <td>0</td>\n      <td>60</td>\n      <td>True</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1877168335193833472</td>\n      <td>https://x.com/JRamirez2O24/status/187716833519...</td>\n      <td>@jdiegol2010 @DanielNoboaOk https://t.co/CsLWQ...</td>\n      <td>True</td>\n      <td>jdiegol2010</td>\n      <td>2025-01-09 01:39:00</td>\n      <td>1759130630766341888</td>\n      <td>ANDRES RAMIREZ</td>\n      <td>JRamirez2O24</td>\n      <td>False</td>\n      <td>...</td>\n      <td>1877115691146306005</td>\n      <td>1877159202646315264</td>\n      <td>2025-01-08 22:10:30</td>\n      <td>208.5</td>\n      <td>321</td>\n      <td>2</td>\n      <td>0</td>\n      <td>51</td>\n      <td>True</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1877159202646315264</td>\n      <td>https://x.com/jdiegol2010/status/1877159202646...</td>\n      <td>@JRamirez2O24 @DanielNoboaOk El tema es respet...</td>\n      <td>True</td>\n      <td>JRamirez2O24</td>\n      <td>2025-01-09 01:03:00</td>\n      <td>146111157</td>\n      <td>Juan Diego</td>\n      <td>jdiegol2010</td>\n      <td>False</td>\n      <td>...</td>\n      <td>1877115691146306005</td>\n      <td>1877130145938481152</td>\n      <td>2025-01-08 22:10:30</td>\n      <td>172.5</td>\n      <td>5343</td>\n      <td>2</td>\n      <td>0</td>\n      <td>80</td>\n      <td>True</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1877149313287016704</td>\n      <td>https://x.com/JRamirez2O24/status/187714931328...</td>\n      <td>@gladiadorjavier @DanielNoboaOk Yo no lo he vi...</td>\n      <td>True</td>\n      <td>gladiadorjavier</td>\n      <td>2025-01-09 00:24:00</td>\n      <td>1759130630766341888</td>\n      <td>ANDRES RAMIREZ</td>\n      <td>JRamirez2O24</td>\n      <td>False</td>\n      <td>...</td>\n      <td>1877115691146306005</td>\n      <td>1877133217800622336</td>\n      <td>2025-01-08 22:10:30</td>\n      <td>133.5</td>\n      <td>321</td>\n      <td>2</td>\n      <td>0</td>\n      <td>63</td>\n      <td>True</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1877149210715320832</td>\n      <td>https://x.com/JRamirez2O24/status/187714921071...</td>\n      <td>@gladiadorjavier @DanielNoboaOk Pero NOBOA sig...</td>\n      <td>True</td>\n      <td>gladiadorjavier</td>\n      <td>2025-01-09 00:23:00</td>\n      <td>1759130630766341888</td>\n      <td>ANDRES RAMIREZ</td>\n      <td>JRamirez2O24</td>\n      <td>False</td>\n      <td>...</td>\n      <td>1877115691146306005</td>\n      <td>1877133217800622336</td>\n      <td>2025-01-08 22:10:30</td>\n      <td>132.5</td>\n      <td>321</td>\n      <td>2</td>\n      <td>0</td>\n      <td>81</td>\n      <td>True</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1877135113193943296</td>\n      <td>https://x.com/JaimeEspin13/status/187713511319...</td>\n      <td>@Isaac_25_1986 @brillosaaa @DanielNoboaOk Una ...</td>\n      <td>True</td>\n      <td>Isaac_25_1986</td>\n      <td>2025-01-08 23:27:00</td>\n      <td>1782790335048884224</td>\n      <td>Jaime Esp√≠n</td>\n      <td>JaimeEspin13</td>\n      <td>False</td>\n      <td>...</td>\n      <td>1877115691146306005</td>\n      <td>1877131823412654080</td>\n      <td>2025-01-08 22:10:30</td>\n      <td>76.5</td>\n      <td>256</td>\n      <td>3</td>\n      <td>0</td>\n      <td>196</td>\n      <td>True</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1877133217800622336</td>\n      <td>https://x.com/gladiadorjavier/status/187713321...</td>\n      <td>@JRamirez2O24 @DanielNoboaOk https://t.co/zLgW...</td>\n      <td>True</td>\n      <td>JRamirez2O24</td>\n      <td>2025-01-08 23:20:00</td>\n      <td>187716489</td>\n      <td>PARDES</td>\n      <td>gladiadorjavier</td>\n      <td>False</td>\n      <td>...</td>\n      <td>1877115691146306005</td>\n      <td>1877132922299335168</td>\n      <td>2025-01-08 22:10:30</td>\n      <td>69.5</td>\n      <td>5234</td>\n      <td>2</td>\n      <td>0</td>\n      <td>52</td>\n      <td>True</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1877133121360986368</td>\n      <td>https://x.com/Diegoelbroko/status/187713312136...</td>\n      <td>@Jorgelr79 @FunerariaAlach @DanielNoboaOk Para...</td>\n      <td>True</td>\n      <td>Jorgelr79</td>\n      <td>2025-01-08 23:19:00</td>\n      <td>1578115618452250624</td>\n      <td>Diego Zeballos</td>\n      <td>Diegoelbroko</td>\n      <td>False</td>\n      <td>...</td>\n      <td>1877115691146306005</td>\n      <td>1877129082955006464</td>\n      <td>2025-01-08 22:10:30</td>\n      <td>68.5</td>\n      <td>821</td>\n      <td>3</td>\n      <td>0</td>\n      <td>312</td>\n      <td>True</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows √ó 26 columns</p>\n</div>\n```\n:::\n:::\n\n\n# Informaci√≥n general del dataset\n\n::: {#1677f8fa .cell execution_count=9}\n``` {.python .cell-code}\ndf.info()     # Quarto debe capturarlo; si no ves nada, usa la versi√≥n con buffer:\n# import io\n# buf = io.StringIO()\n# df.info(buf=buf)\n# print(buf.getvalue())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 158873 entries, 0 to 158872\nData columns (total 26 columns):\n #   Column               Non-Null Count   Dtype  \n---  ------               --------------   -----  \n 0   tweetId              158873 non-null  int64  \n 1   tweetUrl             158873 non-null  object \n 2   content              158873 non-null  object \n 3   isReply              158873 non-null  bool   \n 4   replyTo              158011 non-null  object \n 5   createdAt            158873 non-null  object \n 6   authorId             158873 non-null  int64  \n 7   authorName           158871 non-null  object \n 8   authorUsername       158873 non-null  object \n 9   authorVerified       158873 non-null  bool   \n 10  authorFollowers      158873 non-null  int64  \n 11  authorProfilePic     158873 non-null  object \n 12  authorJoinDate       158873 non-null  object \n 13  source               158873 non-null  object \n 14  hashtags             12415 non-null   object \n 15  mentions             158525 non-null  object \n 16  conversationId       158873 non-null  int64  \n 17  inReplyToId          158873 non-null  int64  \n 18  Date                 158873 non-null  object \n 19  time_response        158873 non-null  float64\n 20  account_age_days     158873 non-null  int64  \n 21  mentions_count       158873 non-null  int64  \n 22  hashtags_count       158873 non-null  int64  \n 23  content_length       158873 non-null  int64  \n 24  has_profile_picture  158873 non-null  bool   \n 25  sentiment_polarity   158873 non-null  float64\ndtypes: bool(3), float64(2), int64(9), object(12)\nmemory usage: 28.3+ MB\n```\n:::\n:::\n\n\n# Cantidad de filas y columnas\n\n::: {#010c8993 .cell execution_count=10}\n``` {.python .cell-code}\nprint(\"Shape:\", df.shape)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nShape: (158873, 26)\n```\n:::\n:::\n\n\n# Verificar nombres de columnas\n\n::: {#86abc7b9 .cell execution_count=11}\n``` {.python .cell-code}\nlist(df.columns)\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```\n['tweetId',\n 'tweetUrl',\n 'content',\n 'isReply',\n 'replyTo',\n 'createdAt',\n 'authorId',\n 'authorName',\n 'authorUsername',\n 'authorVerified',\n 'authorFollowers',\n 'authorProfilePic',\n 'authorJoinDate',\n 'source',\n 'hashtags',\n 'mentions',\n 'conversationId',\n 'inReplyToId',\n 'Date',\n 'time_response',\n 'account_age_days',\n 'mentions_count',\n 'hashtags_count',\n 'content_length',\n 'has_profile_picture',\n 'sentiment_polarity']\n```\n:::\n:::\n\n\n## Exploraci√≥n del target potencial\n\n::: {#a5e594de .cell execution_count=12}\n``` {.python .cell-code}\n# Revisar la variaci√≥n de sentiment_polarity\nprint(df['sentiment_polarity'].describe())\n\nprint(\"\\nValores √∫nicos de sentiment_polarity y su frecuencia:\")\nprint(df['sentiment_polarity'].value_counts().head(10))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ncount    158873.000000\nmean         -0.010103\nstd           0.118703\nmin          -1.000000\n25%           0.000000\n50%           0.000000\n75%           0.000000\nmax           1.000000\nName: sentiment_polarity, dtype: float64\n\nValores √∫nicos de sentiment_polarity y su frecuencia:\nsentiment_polarity\n 0.000000    152896\n-1.000000      1411\n 0.200000       559\n-0.500000       549\n-0.100000       430\n 0.033333       285\n-0.400000       264\n 0.500000       178\n-0.800000       168\n 0.375000       164\nName: count, dtype: int64\n```\n:::\n:::\n\n\n## Borrar columnas irrelevantes\n\n::: {#d51c4103 .cell execution_count=13}\n``` {.python .cell-code}\n# === Eliminaci√≥n expl√≠cita de columnas irrelevantes ===\nirrelevantes = [\n    'tweetId', 'tweetUrl',                 # IDs/URLs\n    'authorId', 'authorName', 'authorUsername', 'authorProfilePic',\n    'replyTo', 'conversationId', 'inReplyToId',                      # IDs de conversaci√≥n\n    'createdAt', 'Date', 'authorJoinDate',                           # timestamps en texto\n    'mentions', 'hashtags',                                          # ya tenemos *_count\n    'source'                                                         # casi constante\n    # 'content_length'  # <- si NO quieres usarla, descomenta y se elimina\n]\n\n# Columnas relevantes que conservaremos\nrelevantes = [\n    'content', 'isReply', 'authorVerified', 'has_profile_picture',\n    'authorFollowers', 'account_age_days', 'mentions_count',\n    'hashtags_count', 'time_response', 'content_length',\n    'sentiment_polarity'\n]\n\ncols_existentes = [c for c in irrelevantes if c in df.columns]\ndf_clean = df.drop(columns=cols_existentes).copy()\ndf_clean = df_clean[relevantes].copy()\n\nprint(\"Eliminadas:\", len(cols_existentes), \"‚Üí\", cols_existentes)\nprint(\"Shape original:\", df.shape, \"‚Üí Shape limpio:\", df_clean.shape)\ndisplay(df_clean.head(3))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEliminadas: 15 ‚Üí ['tweetId', 'tweetUrl', 'authorId', 'authorName', 'authorUsername', 'authorProfilePic', 'replyTo', 'conversationId', 'inReplyToId', 'createdAt', 'Date', 'authorJoinDate', 'mentions', 'hashtags', 'source']\nShape original: (158873, 26) ‚Üí Shape limpio: (158873, 11)\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n      <th>isReply</th>\n      <th>authorVerified</th>\n      <th>has_profile_picture</th>\n      <th>authorFollowers</th>\n      <th>account_age_days</th>\n      <th>mentions_count</th>\n      <th>hashtags_count</th>\n      <th>time_response</th>\n      <th>content_length</th>\n      <th>sentiment_polarity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@DiegoPonguill10 @DanielNoboaOk @LuisaGonzalez...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>145</td>\n      <td>1151</td>\n      <td>3</td>\n      <td>0</td>\n      <td>298.5</td>\n      <td>88</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@hectorjalonm @DanielNoboaOk @LuisaGonzalezEc ...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>176</td>\n      <td>883</td>\n      <td>3</td>\n      <td>0</td>\n      <td>288.5</td>\n      <td>119</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@Gregori58965636 @yesendiaz @DanielNoboaOk Otr...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>147</td>\n      <td>1153</td>\n      <td>3</td>\n      <td>0</td>\n      <td>279.5</td>\n      <td>60</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Crear target \"user_type\"\n\n::: {#4caa983e .cell execution_count=14}\n``` {.python .cell-code}\n# Heur√≠stica para etiquetar \"bot\" vs \"real\"\ndef label_user_type(row):\n    score = 0\n    # se√±ales fuertes\n    if not row['has_profile_picture']:\n        score += 2\n    if row['authorFollowers'] < 50:\n        score += 2\n    if row['account_age_days'] < 60:\n        score += 2\n    # se√±ales adicionales\n    if row['mentions_count'] >= 3:\n        score += 1\n    if row['hashtags_count'] >= 3:\n        score += 1\n    if row['content_length'] < 20:\n        score += 1\n    if row['isReply']:\n        score += 1\n    # verificado resta (suele ser humano/organizaci√≥n)\n    if row['authorVerified']:\n        score -= 2\n\n    return \"bot\" if score >= 4 else \"real\"\n\ndf_bot = df_clean.copy()\ndf_bot['user_type'] = df_bot.apply(label_user_type, axis=1)\n\nprint(\"Distribuci√≥n user_type:\")\nprint(df_bot['user_type'].value_counts())\nprint(\"\\nProporciones:\")\nprint(df_bot['user_type'].value_counts(normalize=True).round(3))\n\n# --- Gr√°fico: Distribuci√≥n de clases (user_type) ---\nimport matplotlib.pyplot as plt\n\nax = df_bot['user_type'].value_counts().plot(kind='bar')\nplt.title('Distribuci√≥n de clases (user_type)')\nplt.xlabel('Clase')\nplt.ylabel('Frecuencia')\nplt.tight_layout()\nplt.show()\n\n# (opcional) guardar la figura para tu informe/presentaci√≥n\nfig = plt.gcf()\nfig.savefig(\"docs/fig_user_type_dist.png\", dpi=150, bbox_inches='tight')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDistribuci√≥n user_type:\nuser_type\nreal    126836\nbot      32037\nName: count, dtype: int64\n\nProporciones:\nuser_type\nreal    0.798\nbot     0.202\nName: proportion, dtype: float64\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](tweets_classification_files/figure-html/cell-15-output-2.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n```\n<Figure size 672x480 with 0 Axes>\n```\n:::\n:::\n\n\n## Seleccion de columnas para entrenar\n\n::: {#2068ff28 .cell execution_count=15}\n``` {.python .cell-code}\n# Definici√≥n de columnas\ntext_col = 'content'\ntarget_col = 'user_type'\n\ncat_cols = ['isReply', 'authorVerified']\nnum_cols = ['authorFollowers', 'mentions_count', 'hashtags_count', 'time_response', 'content_length']\n\nkeep_cols = [text_col, target_col] + cat_cols + num_cols\ndf_train = df_bot[keep_cols].copy()\n\n# Limpieza m√≠nima\ndf_train[text_col] = df_train[text_col].fillna(\"\").astype(str).str.strip()\ndf_train = df_train[df_train[text_col] != \"\"]\n\nprint(\"Shape final para entrenamiento:\", df_train.shape)\ndisplay(df_train.head(3))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nShape final para entrenamiento: (158873, 9)\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n      <th>user_type</th>\n      <th>isReply</th>\n      <th>authorVerified</th>\n      <th>authorFollowers</th>\n      <th>mentions_count</th>\n      <th>hashtags_count</th>\n      <th>time_response</th>\n      <th>content_length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@DiegoPonguill10 @DanielNoboaOk @LuisaGonzalez...</td>\n      <td>real</td>\n      <td>True</td>\n      <td>False</td>\n      <td>145</td>\n      <td>3</td>\n      <td>0</td>\n      <td>298.5</td>\n      <td>88</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@hectorjalonm @DanielNoboaOk @LuisaGonzalezEc ...</td>\n      <td>real</td>\n      <td>True</td>\n      <td>False</td>\n      <td>176</td>\n      <td>3</td>\n      <td>0</td>\n      <td>288.5</td>\n      <td>119</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@Gregori58965636 @yesendiaz @DanielNoboaOk Otr...</td>\n      <td>real</td>\n      <td>True</td>\n      <td>False</td>\n      <td>147</td>\n      <td>3</td>\n      <td>0</td>\n      <td>279.5</td>\n      <td>60</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Train/ Test Split estratificado\n\n::: {#83eb612a .cell execution_count=16}\n``` {.python .cell-code}\nfrom sklearn.model_selection import train_test_split\n\nX = df_train.drop(columns=[target_col])\ny = df_train[target_col]\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\nprint(\"Train:\", X_train.shape, \" Test:\", X_test.shape)\nprint(\"Distrib y_train:\\n\", y_train.value_counts(normalize=True).round(3))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTrain: (127098, 8)  Test: (31775, 8)\nDistrib y_train:\n user_type\nreal    0.798\nbot     0.202\nName: proportion, dtype: float64\n```\n:::\n:::\n\n\n## ColumnTransformer (TF-IDF + OHE + escala num√©rica)\n\n::: {#9d117577 .cell execution_count=17}\n``` {.python .cell-code}\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom nltk.corpus import stopwords as nltk_stopwords   # ‚¨ÖÔ∏è NUEVO\n\nspanish_stop = nltk_stopwords.words('spanish')        # ‚¨ÖÔ∏è NUEVO\n\ntext_vectorizer = TfidfVectorizer(\n    stop_words=spanish_stop,      # ‚¨ÖÔ∏è en lugar de 'spanish'\n    min_df=5,\n    max_df=0.90,\n    ngram_range=(1, 2),\n    max_features=50000\n)\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('text', text_vectorizer, text_col),\n        ('cat', OneHotEncoder(handle_unknown='ignore', drop='if_binary'), cat_cols),\n        ('num', StandardScaler(with_mean=False), num_cols)\n    ],\n    remainder='drop',\n    sparse_threshold=0.3\n)\n\n```\n:::\n\n\n## Pipelines (LR con texto+meta, y NB solo texto)\n\n::: {#dfe889e9 .cell execution_count=18}\n``` {.python .cell-code}\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\n\n# Regresi√≥n Log√≠stica (texto + categ√≥ricas + num√©ricas)\npipe_lr = Pipeline([\n    ('prep', preprocessor),\n    ('clf', LogisticRegression(\n        max_iter=10000,\n        class_weight={'bot': 2.5, 'real': 1.0},\n        random_state=42\n    ))\n])\n\n\n# Naive Bayes SOLO TEXTO (baseline)\npipe_nb_text_only = Pipeline([\n    ('tfidf', text_vectorizer),\n    ('nb', MultinomialNB())\n])\n```\n:::\n\n\n## Entrenar y Evaluar\n\n::: {#ffdfca15 .cell execution_count=19}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report, ConfusionMatrixDisplay\n\n# 1) Logistic Regression con todas las features\npipe_lr.fit(X_train, y_train)\ny_pred_lr = pipe_lr.predict(X_test)\nprint(\"=== Logistic Regression (texto + meta) ===\")\nprint(classification_report(y_test, y_pred_lr, digits=3))\nConfusionMatrixDisplay.from_predictions(y_test, y_pred_lr)\nplt.show()\n\n# 2) Naive Bayes solo texto\npipe_nb_text_only.fit(X_train[text_col], y_train)\ny_pred_nb = pipe_nb_text_only.predict(X_test[text_col])\nprint(\"\\n=== MultinomialNB (solo texto) ===\")\nprint(classification_report(y_test, y_pred_nb, digits=3))\nConfusionMatrixDisplay.from_predictions(y_test, y_pred_nb)\nplt.show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n=== Logistic Regression (texto + meta) ===\n              precision    recall  f1-score   support\n\n         bot      0.557     0.543     0.550      6407\n        real      0.885     0.891     0.888     25368\n\n    accuracy                          0.821     31775\n   macro avg      0.721     0.717     0.719     31775\nweighted avg      0.819     0.821     0.820     31775\n\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](tweets_classification_files/figure-html/cell-20-output-2.png){}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n=== MultinomialNB (solo texto) ===\n              precision    recall  f1-score   support\n\n         bot      0.706     0.218     0.334      6407\n        real      0.832     0.977     0.899     25368\n\n    accuracy                          0.824     31775\n   macro avg      0.769     0.598     0.616     31775\nweighted avg      0.807     0.824     0.785     31775\n\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](tweets_classification_files/figure-html/cell-20-output-4.png){}\n:::\n:::\n\n\n# Resultados y An√°lisis\n\nEl dataset de Twitter contiene **158 873 registros** con texto y metadatos de usuarios.  \nSe defini√≥ un target heur√≠stico `user_type` (real vs bot) basado en reglas simples de comportamiento y atributos del perfil.\n\n### Distribuci√≥n de clases\nEl conjunto de datos qued√≥ con una proporci√≥n aproximada de **80 % usuarios reales** y **20 % bots**, lo que permite entrenar sin balance extremo.\n\n### Modelos evaluados\nSe compararon dos enfoques:\n- **Multinomial Naive Bayes** (solo texto, TF-IDF)\n- **Regresi√≥n Log√≠stica** (texto + variables categ√≥ricas y num√©ricas)\n\n### Desempe√±o general\nEl modelo **Logistic Regression (texto + meta)** logr√≥ un mejor balance entre precisi√≥n y recall, alcanzando un `accuracy ‚âà 0.82` y mejor detecci√≥n de la clase *bot* (`recall ‚âà 0.54` frente a `0.21` en NB).  \nEl uso de **bigramas** y **stopwords en espa√±ol** mejor√≥ la se√±al textual, y el ajuste de pesos (`class_weight`) aument√≥ la sensibilidad hacia *bot*.\n\n### Conclusiones\n- Las variables de perfil (`followers`, `account_age_days`, `verified`) complementan al texto para identificar bots.\n- La etiqueta heur√≠stica es √∫til para experimentaci√≥n, aunque no reemplaza una anotaci√≥n humana.\n- Logistic Regression es m√°s estable que Naive Bayes en contextos con metadatos.\n- Se podr√≠an probar mejoras con t√©cnicas de balanceo (SMOTE, undersampling) o modelos no lineales (√°rboles, boosting).\n\n### Trabajo futuro\n- Refinar la heur√≠stica del target con detecci√≥n semiautom√°tica.\n- Evaluar interpretabilidad con `coef_` de LR (palabras m√°s predictivas).\n- Publicar resultados interactivos en el dashboard Quarto.\n\n",
    "supporting": [
      "tweets_classification_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdn.jsdelivr.net/npm/requirejs@2.3.6/require.min.js\" integrity=\"sha384-c9c+LnTbwQ3aujuU7ULEPVvgLs+Fn6fJUvIGTsuu1ZcCf11fiEubah0ttpca4ntM sha384-6V1/AdqZRWk1KAlWbKBlGhN7VG4iE/yAZcO6NZPMF8od0vukrvr0tg4qY6NSrItx\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js\" integrity=\"sha384-ZvpUoO/+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn/6Z/hRTt8+pR6L4N2\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}