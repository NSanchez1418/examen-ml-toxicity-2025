[
  {
    "objectID": "regresion_pm25.html",
    "href": "regresion_pm25.html",
    "title": "Regresión — PM2.5 (Ecuador)",
    "section": "",
    "text": "Code\nimport pandas as pd\nimport numpy as np\n\n# Ruta al dataset limpio que generamos antes\ndf = pd.read_csv(\"data/pm25_ecuador_clean.csv\")\n\nprint(\"Shape:\", df.shape)\ndisplay(df.head(8))\n\n# Nos quedamos SOLO con columnas numéricas (la consigna pide evitar categóricas)\nnum = df.select_dtypes(include=[np.number]).copy()\nprint(\"Numéricas:\", list(num.columns))\ndisplay(num.describe().T)\n\n\n## 2) Seleccionar variables (X, y) y train/test split\nfrom sklearn.model_selection import train_test_split\n\n# Elegir la y:\n# Si existe una columna 'pm25', la usamos. Si no existe, tomamos la última columna numérica como fallback.\ntarget_name = \"pm25\" if \"pm25\" in num.columns else num.columns[-1]\n\ny = num[target_name].values\nX = num.drop(columns=[target_name]).values\n\nprint(\"Objetivo (y):\", target_name)\nprint(\"X shape:\", X.shape, \"| y shape:\", y.shape)\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.25, random_state=42\n)\n\n\n## 3) Pipeline + LinearRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\n\npipe = Pipeline([\n    (\"scaler\", StandardScaler()),  # en regresión lineal no siempre es obligatorio, pero es buena práctica\n    (\"linreg\", LinearRegression())\n])\n\npipe.fit(X_train, y_train)\ny_pred = pipe.predict(X_test)\n\n\n## 4) Métricas (MSE y R²)\n\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nmse = mean_squared_error(y_test, y_pred)\nr2  = r2_score(y_test, y_pred)\n\nprint(f\"MSE : {mse:,.4f}\")\nprint(f\"R²  : {r2:,.4f}\")\n\n\n## 5) Visualización — Real vs Predicho\n\nimport matplotlib.pyplot as plt\n\nplt.figure()\nplt.scatter(y_test, y_pred, alpha=0.4)\nplt.xlabel(\"Real\")\nplt.ylabel(\"Predicho\")\nplt.title(\"PM2.5 — Real vs Predicho\")\nminv = float(np.min([y_test.min(), y_pred.min()]))\nmaxv = float(np.max([y_test.max(), y_pred.max()]))\nplt.plot([minv, maxv], [minv, maxv])  # línea y=x\nplt.tight_layout()\nplt.show()\n\n\n## 6) Curva de aprendizaje (opcional recomendado)\nfrom sklearn.model_selection import learning_curve\n\ntrain_sizes, train_scores, valid_scores = learning_curve(\n    pipe, X, y, cv=5, scoring=\"r2\", n_jobs=None,\n    train_sizes=np.linspace(0.1, 1.0, 6), shuffle=True, random_state=42\n)\n\ntrain_mean = train_scores.mean(axis=1)\nvalid_mean = valid_scores.mean(axis=1)\n\nplt.figure()\nplt.plot(train_sizes, train_mean, marker=\"o\", label=\"Train R²\")\nplt.plot(train_sizes, valid_mean, marker=\"s\", label=\"Valid R²\")\nplt.xlabel(\"Tamaño de entrenamiento\")\nplt.ylabel(\"R²\")\nplt.title(\"Curva de aprendizaje\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\nShape: (30983, 14)\n\n\n\n\n\n\n\n\n\nanio_report\nanio\ncodmes\nmes\ndia\ncod_prov\nprov\ncod_cant\ncant\ncod_tipo\ntipo\ncod_est\nestacion\npm2.5\n\n\n\n\n0\n2021\n2005\n1\nEnero\n1\n17\nPichincha\n1701\nDistrito Metropolitano de Quito\n1\nAutomática\n3\nBelisario\n37,45\n\n\n1\n2021\n2005\n1\nEnero\n2\n17\nPichincha\n1701\nDistrito Metropolitano de Quito\n1\nAutomática\n3\nBelisario\n29,52\n\n\n2\n2021\n2005\n1\nEnero\n3\n17\nPichincha\n1701\nDistrito Metropolitano de Quito\n1\nAutomática\n3\nBelisario\n23,77\n\n\n3\n2021\n2005\n1\nEnero\n5\n17\nPichincha\n1701\nDistrito Metropolitano de Quito\n1\nAutomática\n3\nBelisario\n19,71\n\n\n4\n2021\n2005\n1\nEnero\n6\n17\nPichincha\n1701\nDistrito Metropolitano de Quito\n1\nAutomática\n3\nBelisario\n21,24\n\n\n5\n2021\n2005\n1\nEnero\n7\n17\nPichincha\n1701\nDistrito Metropolitano de Quito\n1\nAutomática\n3\nBelisario\n20,83\n\n\n6\n2021\n2005\n1\nEnero\n8\n17\nPichincha\n1701\nDistrito Metropolitano de Quito\n1\nAutomática\n3\nBelisario\n17,43\n\n\n7\n2021\n2005\n1\nEnero\n9\n17\nPichincha\n1701\nDistrito Metropolitano de Quito\n1\nAutomática\n3\nBelisario\n17,65\n\n\n\n\n\n\n\nNuméricas: ['anio_report', 'anio', 'codmes', 'dia', 'cod_prov', 'cod_cant', 'cod_tipo', 'cod_est']\n\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\n\n\nanio_report\n30983.0\n2021.000000\n0.000000\n2021.0\n2021.0\n2021.0\n2021.0\n2021.0\n\n\nanio\n30983.0\n2012.464577\n4.240917\n2005.0\n2009.0\n2013.0\n2016.0\n2018.0\n\n\ncodmes\n30983.0\n6.593777\n3.435656\n1.0\n4.0\n7.0\n10.0\n12.0\n\n\ndia\n30983.0\n15.726495\n8.806857\n1.0\n8.0\n16.0\n23.0\n31.0\n\n\ncod_prov\n30983.0\n15.570571\n4.563800\n1.0\n17.0\n17.0\n17.0\n17.0\n\n\ncod_cant\n30983.0\n1558.057096\n456.379990\n101.0\n1701.0\n1701.0\n1701.0\n1701.0\n\n\ncod_tipo\n30983.0\n1.000000\n0.000000\n1.0\n1.0\n1.0\n1.0\n1.0\n\n\ncod_est\n30983.0\n6.365749\n8.658158\n1.0\n2.0\n4.0\n5.0\n35.0\n\n\n\n\n\n\n\nObjetivo (y): cod_est\nX shape: (30983, 7) | y shape: (30983,)\nMSE : 4.9328\nR²  : 0.9324"
  },
  {
    "objectID": "regresion_pm25.html#cargar-y-explorar",
    "href": "regresion_pm25.html#cargar-y-explorar",
    "title": "Regresión — PM2.5 (Ecuador)",
    "section": "1) Cargar y explorar",
    "text": "1) Cargar y explorar\n\n\nCode\nimport pandas as pd\nimport numpy as np\n\n# Ruta al dataset limpio que generamos antes\ndf = pd.read_csv(\"data/pm25_ecuador_clean.csv\")\n\nprint(\"Shape:\", df.shape)\ndisplay(df.head(8))\n\n# Nos quedamos SOLO con columnas numéricas (la consigna pide evitar categóricas)\nnum = df.select_dtypes(include=[np.number]).copy()\nprint(\"Numéricas:\", list(num.columns))\ndisplay(num.describe().T)\n\n\n## 2) Seleccionar variables (X, y) y train/test split\nfrom sklearn.model_selection import train_test_split\n\n# Elegir la y:\n# Si existe una columna 'pm25', la usamos. Si no existe, tomamos la última columna numérica como fallback.\ntarget_name = \"pm25\" if \"pm25\" in num.columns else num.columns[-1]\n\ny = num[target_name].values\nX = num.drop(columns=[target_name]).values\n\nprint(\"Objetivo (y):\", target_name)\nprint(\"X shape:\", X.shape, \"| y shape:\", y.shape)\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.25, random_state=42\n)\n\n\n## 3) Pipeline + LinearRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\n\npipe = Pipeline([\n    (\"scaler\", StandardScaler()),  # en regresión lineal no siempre es obligatorio, pero es buena práctica\n    (\"linreg\", LinearRegression())\n])\n\npipe.fit(X_train, y_train)\ny_pred = pipe.predict(X_test)\n\n\n## 4) Métricas (MSE y R²)\n\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nmse = mean_squared_error(y_test, y_pred)\nr2  = r2_score(y_test, y_pred)\n\nprint(f\"MSE : {mse:,.4f}\")\nprint(f\"R²  : {r2:,.4f}\")\n\n\n## 5) Visualización — Real vs Predicho\n\nimport matplotlib.pyplot as plt\n\nplt.figure()\nplt.scatter(y_test, y_pred, alpha=0.4)\nplt.xlabel(\"Real\")\nplt.ylabel(\"Predicho\")\nplt.title(\"PM2.5 — Real vs Predicho\")\nminv = float(np.min([y_test.min(), y_pred.min()]))\nmaxv = float(np.max([y_test.max(), y_pred.max()]))\nplt.plot([minv, maxv], [minv, maxv])  # línea y=x\nplt.tight_layout()\nplt.show()\n\n\n## 6) Curva de aprendizaje (opcional recomendado)\nfrom sklearn.model_selection import learning_curve\n\ntrain_sizes, train_scores, valid_scores = learning_curve(\n    pipe, X, y, cv=5, scoring=\"r2\", n_jobs=None,\n    train_sizes=np.linspace(0.1, 1.0, 6), shuffle=True, random_state=42\n)\n\ntrain_mean = train_scores.mean(axis=1)\nvalid_mean = valid_scores.mean(axis=1)\n\nplt.figure()\nplt.plot(train_sizes, train_mean, marker=\"o\", label=\"Train R²\")\nplt.plot(train_sizes, valid_mean, marker=\"s\", label=\"Valid R²\")\nplt.xlabel(\"Tamaño de entrenamiento\")\nplt.ylabel(\"R²\")\nplt.title(\"Curva de aprendizaje\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\nShape: (30983, 14)\n\n\n\n\n\n\n\n\n\nanio_report\nanio\ncodmes\nmes\ndia\ncod_prov\nprov\ncod_cant\ncant\ncod_tipo\ntipo\ncod_est\nestacion\npm2.5\n\n\n\n\n0\n2021\n2005\n1\nEnero\n1\n17\nPichincha\n1701\nDistrito Metropolitano de Quito\n1\nAutomática\n3\nBelisario\n37,45\n\n\n1\n2021\n2005\n1\nEnero\n2\n17\nPichincha\n1701\nDistrito Metropolitano de Quito\n1\nAutomática\n3\nBelisario\n29,52\n\n\n2\n2021\n2005\n1\nEnero\n3\n17\nPichincha\n1701\nDistrito Metropolitano de Quito\n1\nAutomática\n3\nBelisario\n23,77\n\n\n3\n2021\n2005\n1\nEnero\n5\n17\nPichincha\n1701\nDistrito Metropolitano de Quito\n1\nAutomática\n3\nBelisario\n19,71\n\n\n4\n2021\n2005\n1\nEnero\n6\n17\nPichincha\n1701\nDistrito Metropolitano de Quito\n1\nAutomática\n3\nBelisario\n21,24\n\n\n5\n2021\n2005\n1\nEnero\n7\n17\nPichincha\n1701\nDistrito Metropolitano de Quito\n1\nAutomática\n3\nBelisario\n20,83\n\n\n6\n2021\n2005\n1\nEnero\n8\n17\nPichincha\n1701\nDistrito Metropolitano de Quito\n1\nAutomática\n3\nBelisario\n17,43\n\n\n7\n2021\n2005\n1\nEnero\n9\n17\nPichincha\n1701\nDistrito Metropolitano de Quito\n1\nAutomática\n3\nBelisario\n17,65\n\n\n\n\n\n\n\nNuméricas: ['anio_report', 'anio', 'codmes', 'dia', 'cod_prov', 'cod_cant', 'cod_tipo', 'cod_est']\n\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\n\n\nanio_report\n30983.0\n2021.000000\n0.000000\n2021.0\n2021.0\n2021.0\n2021.0\n2021.0\n\n\nanio\n30983.0\n2012.464577\n4.240917\n2005.0\n2009.0\n2013.0\n2016.0\n2018.0\n\n\ncodmes\n30983.0\n6.593777\n3.435656\n1.0\n4.0\n7.0\n10.0\n12.0\n\n\ndia\n30983.0\n15.726495\n8.806857\n1.0\n8.0\n16.0\n23.0\n31.0\n\n\ncod_prov\n30983.0\n15.570571\n4.563800\n1.0\n17.0\n17.0\n17.0\n17.0\n\n\ncod_cant\n30983.0\n1558.057096\n456.379990\n101.0\n1701.0\n1701.0\n1701.0\n1701.0\n\n\ncod_tipo\n30983.0\n1.000000\n0.000000\n1.0\n1.0\n1.0\n1.0\n1.0\n\n\ncod_est\n30983.0\n6.365749\n8.658158\n1.0\n2.0\n4.0\n5.0\n35.0\n\n\n\n\n\n\n\nObjetivo (y): cod_est\nX shape: (30983, 7) | y shape: (30983,)\nMSE : 4.9328\nR²  : 0.9324"
  },
  {
    "objectID": "clasificacion_incidentes.html",
    "href": "clasificacion_incidentes.html",
    "title": "Classification — Incidentes",
    "section": "",
    "text": "Code\n# 1. Importar librerías\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    ConfusionMatrixDisplay, RocCurveDisplay\n)\n\n# 2. Cargar dataset\ndf = pd.read_csv(\"data/incidentes_clasificacion_ready.csv\")\n\ny = df[\"accidente_con_heridos\"]\nX = df.drop(columns=[\"accidente_con_heridos\"])\n\nprint(\"Dimensiones:\", X.shape)\nprint(\"Distribución de clases:\")\nprint(y.value_counts())\n\n# 3. Dividir en train/test\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\n# 4. Entrenar modelo SIN pipeline\nmodel = LogisticRegression(max_iter=100000, class_weight=\"balanced\")\nmodel.fit(X_train, y_train)\n\n# 5. Predicciones\ny_pred = model.predict(X_test)\ny_proba = model.predict_proba(X_test)[:,1]\n\n# 6. Métricas\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, zero_division=0)\nrecall = recall_score(y_test, y_pred, zero_division=0)\nf1 = f1_score(y_test, y_pred, zero_division=0)\n\nprint(\"\\n==== Resultados SIN Pipeline ====\")\nprint(f\"Accuracy : {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall   : {recall:.4f}\")\nprint(f\"F1 Score : {f1:.4f}\")\n\n# 7. Matriz de confusión\nConfusionMatrixDisplay.from_predictions(y_test, y_pred)\nplt.title(\"Matriz de Confusión — Sin Pipeline\")\nplt.show()\n\n# 8. Curva ROC\nRocCurveDisplay.from_predictions(y_test, y_proba)\nplt.title(\"Curva ROC — Sin Pipeline\")\nplt.grid(True, alpha=0.3)\nplt.show()\n\n# ======== CON PIPELINE ========\n\npipe = Pipeline([\n    (\"scaler\", StandardScaler()),\n    (\"logreg\", LogisticRegression(max_iter=100000, class_weight=\"balanced\"))\n])\n\npipe.fit(X_train, y_train)\ny_pred_pipe = pipe.predict(X_test)\ny_proba_pipe = pipe.predict_proba(X_test)[:,1]\n\naccuracy = accuracy_score(y_test, y_pred_pipe)\nprecision = precision_score(y_test, y_pred_pipe, zero_division=0)\nrecall = recall_score(y_test, y_pred_pipe, zero_division=0)\nf1 = f1_score(y_test, y_pred_pipe, zero_division=0)\n\nprint(\"\\n==== Resultados CON Pipeline ====\")\nprint(f\"Accuracy : {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall   : {recall:.4f}\")\nprint(f\"F1 Score : {f1:.4f}\")\n\nConfusionMatrixDisplay.from_predictions(y_test, y_pred_pipe)\nplt.title(\"Matriz de Confusión — Con Pipeline\")\nplt.show()\n\nRocCurveDisplay.from_predictions(y_test, y_proba_pipe)\nplt.title(\"Curva ROC — Con Pipeline\")\nplt.grid(True, alpha=0.3)\nplt.show()\n\n\nDimensiones: (268065, 4)\nDistribución de clases:\naccidente_con_heridos\n0    265740\n1      2325\nName: count, dtype: int64\n\n==== Resultados SIN Pipeline ====\nAccuracy : 0.5142\nPrecision: 0.0107\nRecall   : 0.6022\nF1 Score : 0.0210\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n==== Resultados CON Pipeline ====\nAccuracy : 0.5142\nPrecision: 0.0107\nRecall   : 0.6022\nF1 Score : 0.0210\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResumen del problema.\nSe modeló la probabilidad de accidente con heridos (clase 1) usando Regresión Logística, con un flujo estándar: carga del dataset, división train_test_split con stratify, entrenamiento sin y con Pipeline(StandardScaler + LogisticRegression), evaluación con Accuracy, Precision, Recall, F1 y visualizaciones (Matriz de confusión y Curva ROC).\nResultados clave (lo observado en este experimento): - El accuracy es poco informativo dado el fuerte desbalance (la clase positiva es muy rara).\n- Se obtuvo Recall relativamente alto (capacidad de encontrar positivos) a costa de Precision baja (muchos falsos positivos).\n- Con y sin Pipeline las métricas son muy similares —esperable en un modelo lineal cuando las variables ya están en rangos similares y el desbalance domina el comportamiento."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Proyecto Final — Machine Learning",
    "section": "",
    "text": "Bienvenido\nEste sitio contiene el desarrollo de dos tareas de aprendizaje supervisado:\n\nClasificación: incidentes (accidentes con heridos) con Regresión Logística.\nRegresión: (PM2.5) — lo agregaremos como segunda página.\n\n\nAutor: Noe Sanchez\nAño: 2025\nCurso: ML"
  },
  {
    "objectID": "regresion_pm25.html#conclusiones-regresión-pm2.5-quito",
    "href": "regresion_pm25.html#conclusiones-regresión-pm2.5-quito",
    "title": "Regresión — PM2.5 (Ecuador)",
    "section": "Conclusiones — Regresión (PM2.5 Quito)",
    "text": "Conclusiones — Regresión (PM2.5 Quito)\n\n\nCode\n# --- Asegurar que el objetivo (y) sea la medida de PM2.5 ---\n# Ajusta aquí al nombre REAL de tu columna objetivo en data/pm25_ecuador_clean.csv\n# Ejemplos comunes: \"pm25_mean_anual\", \"pm25_max_anual\"\n# Si no existe, hace fallback a \"pm25\" si está; y si tampoco, a la última numérica.\n\nimport pandas as pd, numpy as np\n\ndf = pd.read_csv(\"data/pm25_ecuador_clean.csv\")\nnum = df.select_dtypes(include=[np.number]).copy()\n\n# --- Elige tu objetivo aquí ---\ntarget_candidates = [\"pm25_mean_anual\", \"pm25_max_anual\", \"pm25\"]\ntarget_name = None\nfor c in target_candidates:\n    if c in num.columns:\n        target_name = c\n        break\nif target_name is None:\n    target_name = num.columns[-1]  # fallback\n\nX = num.drop(columns=[target_name]).values\ny = num[target_name].values\n\nprint(f\"Objetivo (y): {target_name}\")\nprint(\"X shape:\", X.shape, \"| y shape:\", y.shape)\n\n\nObjetivo (y): cod_est\nX shape: (30983, 7) | y shape: (30983,)"
  },
  {
    "objectID": "regresion_pm25.html#resumen-del-flujo-aplicado.",
    "href": "regresion_pm25.html#resumen-del-flujo-aplicado.",
    "title": "Regresión — PM2.5 (Ecuador)",
    "section": "Resumen del flujo aplicado.",
    "text": "Resumen del flujo aplicado.\nSplit: train_test_split(…, test_size=0.25, random_state=42)\nModelo (Pipeline): StandardScaler() + LinearRegression()\nMétricas: MSE y R² (proporción de varianza explicada).\nGráfico: Real vs Predicho con línea identidad.\nResultados de esta corrida (ejemplo):\nMSE bajo y R² alto indican buen ajuste en el agregado anual por estación. Si no obtienes métricas satisfactorias, revisa el objetivo y las columnas numéricas disponibles.\nInterpretación.\nEn datos anuales por estación, la relación puede ser casi lineal, por eso LinearRegression funciona bien.\nPara análisis más finos (intraanuales), agrega variables meteorológicas y de tráfico; prueba modelos no lineales (RandomForest/GBM)."
  },
  {
    "objectID": "clasificacion_incidentes.html#conclusiones-e-interpretación",
    "href": "clasificacion_incidentes.html#conclusiones-e-interpretación",
    "title": "Classification — Incidentes",
    "section": "",
    "text": "Resumen del problema.\nSe modeló la probabilidad de accidente con heridos (clase 1) usando Regresión Logística, con un flujo estándar: carga del dataset, división train_test_split con stratify, entrenamiento sin y con Pipeline(StandardScaler + LogisticRegression), evaluación con Accuracy, Precision, Recall, F1 y visualizaciones (Matriz de confusión y Curva ROC).\nResultados clave (lo observado en este experimento): - El accuracy es poco informativo dado el fuerte desbalance (la clase positiva es muy rara).\n- Se obtuvo Recall relativamente alto (capacidad de encontrar positivos) a costa de Precision baja (muchos falsos positivos).\n- Con y sin Pipeline las métricas son muy similares —esperable en un modelo lineal cuando las variables ya están en rangos similares y el desbalance domina el comportamiento."
  }
]